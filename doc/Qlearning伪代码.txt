用latex

Inputs: F;L; for a state-action pair (s,a) Vs属于S, a属于A,then initialize a Q-table entry with Q(s,a) value arbitrarily,a and e, respectively.
begin
Repeat the following loop for each episode.
loop
Current state Si.
Execute action ai according an exploratory policy (e)
Obtain the immediate reward ri and new state Si+1.
Update Q(Si,ai) by using Equation 8.Replace si  Si+l.
end loop
Outputs 元*(s) = argmaxa Q(s,a)




输入：
状态空间C值（离散）
动作空间{增加，减少，不变}
特征空间X
标签值y
迭代：
选择动作
    每个动作执行一次svm，记录reward，更新Q值
根据当前迭代更新后的q值获取最佳动作
根据动作确定下次状态值
输出：
best C